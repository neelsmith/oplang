
# Tokenization #

Diplomatic editions of Old Persian texts are conventionally cited by the physical line unit.  



Tokenization follows the explicit conventions of Old Persian
orthography: tokens are delimited by the Old Persian "word divider" character
(in transliteration, ":";  in the Old Persian range of Unicode, "𐏐"
(103D0).

This means that lexical entities written with attached enclitics
are treated as a single token, that can subsequently analyzed as
a composition of two lexical units.

